---
name: Run Eval

on:
    pull_request_target:
        types: [labeled]
    release:
        types: [published]
    workflow_dispatch:
        inputs:
            sdk_ref:
                description: SDK commit/ref to evaluate
                required: true
                default: main
            eval_limit:
                description: Number of SWE-bench instances to run
                required: true
                default: '1'
                type: choice
                options:
                    - '1'
                    - '50'
                    - '200'
                    - '500'
            model_stubs:
                description: Comma-separated model stubs to evaluate (must be allowlisted)
                required: false
                default: ''
                type: string
            reason:
                description: Reason for manual trigger
                required: false
                default: ''

env:
    BENCHMARKS_REPO: OpenHands/benchmarks
    BENCHMARKS_REF: main
    BENCHMARKS_BUILD_WORKFLOW: build-swe-bench-images.yml
    EVAL_REPO: OpenHands/evaluation
    EVAL_WORKFLOW: eval-job.yml
    DATASET: princeton-nlp/SWE-bench_Verified
    SPLIT: test
    MAX_BUILD_WORKERS: '32'
    EVAL_AGENT_IMAGE: ghcr.io/openhands/eval-agent-server
    EVAL_AGENT_TARGET: source-minimal
    # Polling configuration for workflow status checks
    MAX_POLL_ATTEMPTS: '600'  # 600 attempts Ã— 60s = 10 hours max wait
    POLL_INTERVAL_SECONDS: '60'

jobs:
    build-and-evaluate:
        if: >
            github.event_name == 'release' ||
            github.event_name == 'workflow_dispatch' ||
            (github.event_name == 'pull_request_target' &&
             (github.event.label.name == 'run-eval-1' ||
              github.event.label.name == 'run-eval-50' ||
              github.event.label.name == 'run-eval-200' ||
              github.event.label.name == 'run-eval-500'))
        runs-on: ubuntu-latest
        permissions:
            contents: read
            packages: write
            actions: write
            issues: write
            pull-requests: write

        steps:
            - name: Checkout sdk code (base for validation)
              uses: actions/checkout@v4
              with:
                  ref: ${{ github.event_name == 'pull_request_target' && github.event.pull_request.base.sha || (github.event_name == 
                      'workflow_dispatch' && github.event.inputs.sdk_ref) || github.ref }}
                  fetch-depth: 0

            - name: Load allowlists
              id: allowlists
              run: |
                  ALLOWED_MODELS_JSON=$(jq -c '.' .github/run-eval/allowed-model-stubs.json)
                  DEFAULT_MODEL=$(echo "$ALLOWED_MODELS_JSON" | jq -r '.[0]')
                  if [ -z "$DEFAULT_MODEL" ]; then
                    echo "No default model stub configured" >&2
                    exit 1
                  fi
                  echo "allowed_models=$ALLOWED_MODELS_JSON" >> "$GITHUB_OUTPUT"
                  echo "default_model=$DEFAULT_MODEL" >> "$GITHUB_OUTPUT"

            - name: Validate labeler
              if: github.event_name == 'pull_request_target'
              run: |
                  LABELER="${{ github.actor }}"
                  if ! grep -Fx "$LABELER" .github/run-eval/authorized-labelers.txt >/dev/null; then
                    echo "User $LABELER is not authorized to trigger eval." >&2
                    exit 1
                  fi

            - name: Resolve parameters
              id: params
              env:
                  DEFAULT_MODEL: ${{ steps.allowlists.outputs.default_model }}
                  ALLOWED_MODELS_JSON: ${{ steps.allowlists.outputs.allowed_models }}
                  PAT_TOKEN_DEFAULT: ${{ secrets.ALLHANDS_BOT_GITHUB_PAT }}
              run: |
                  set -euo pipefail

                  # Set PAT token for cross-repo workflow dispatch
                  PAT_TOKEN="$PAT_TOKEN_DEFAULT"
                  if [ -z "$PAT_TOKEN" ]; then
                    echo "Missing PAT token" >&2
                    exit 1
                  fi
                  echo "PAT_TOKEN=$PAT_TOKEN" >> "$GITHUB_ENV"

                  # Determine eval limit based on trigger
                  if [ "${{ github.event_name }}" = "pull_request_target" ]; then
                    LABEL="${{ github.event.label.name }}"
                    case "$LABEL" in
                      run-eval-1) EVAL_LIMIT=1 ;;
                      run-eval-50) EVAL_LIMIT=50 ;;
                      run-eval-200) EVAL_LIMIT=200 ;;
                      run-eval-500) EVAL_LIMIT=500 ;;
                      *) echo "Unsupported label $LABEL" >&2; exit 1 ;;
                    esac
                    SDK_REF="${{ github.event.pull_request.head.ref }}"
                    PR_NUMBER="${{ github.event.pull_request.number }}"
                    TRIGGER_DESCRIPTION="Label '${LABEL}' on PR #${PR_NUMBER}"
                  elif [ "${{ github.event_name }}" = "release" ]; then
                    EVAL_LIMIT=50
                    SDK_REF="${{ github.event.release.tag_name }}"
                    PR_NUMBER=""
                    TRIGGER_DESCRIPTION="Release ${{ github.event.release.tag_name }}"
                  else
                    EVAL_LIMIT="${{ github.event.inputs.eval_limit }}"
                    SDK_REF="${{ github.event.inputs.sdk_ref }}"
                    PR_NUMBER=""
                    REASON="${{ github.event.inputs.reason }}"
                    if [ -z "$REASON" ]; then
                      REASON="manual"
                    fi
                    TRIGGER_DESCRIPTION="Manual trigger: ${REASON}"
                  fi

                  # Normalize and validate models
                  MODELS_INPUT="${{ github.event_name == 'workflow_dispatch' && github.event.inputs.model_stubs || '' }}"
                  if [ -z "$MODELS_INPUT" ]; then
                    MODELS_INPUT="$DEFAULT_MODEL"
                  fi
                  MODELS=$(printf '%s' "$MODELS_INPUT" | tr ', ' '\n' | sed '/^$/d' | paste -sd, -)
                  ALLOWED_LIST=$(echo "$ALLOWED_MODELS_JSON" | jq -r '.[]')
                  for MODEL in ${MODELS//,/ }; do
                    if ! echo "$ALLOWED_LIST" | grep -Fx "$MODEL" >/dev/null; then
                      echo "Model stub '$MODEL' is not allowlisted" >&2
                      exit 1
                    fi
                  done

                  echo "eval_limit=$EVAL_LIMIT" >> "$GITHUB_OUTPUT"
                  echo "sdk_ref=$SDK_REF" >> "$GITHUB_OUTPUT"
                  echo "models=$MODELS" >> "$GITHUB_OUTPUT"
                  echo "pr_number=$PR_NUMBER" >> "$GITHUB_OUTPUT"
                  echo "trigger_desc=$TRIGGER_DESCRIPTION" >> "$GITHUB_OUTPUT"

            - name: Checkout evaluated ref for PRs
              if: github.event_name == 'pull_request_target'
              run: |
                  set -euo pipefail
                  # Switch to the PR head for image build and SDK pinning.
                  REF="${{ steps.params.outputs.sdk_ref }}"
                  git fetch origin "$REF" --force
                  git checkout FETCH_HEAD

            - name: Get current commit SHA
              id: get-sha
              run: |
                  SDK_SHA=$(git rev-parse HEAD)
                  echo "sdk_sha=$SDK_SHA" >> "$GITHUB_OUTPUT"
                  echo "Using SDK commit: $SDK_SHA"

            - name: Dispatch benchmarks image build
              id: build-dispatch
              env:
                  EVAL_LIMIT: ${{ steps.params.outputs.eval_limit }}
                  DATASET: ${{ env.DATASET }}
                  SPLIT: ${{ env.SPLIT }}
                  MAX_BUILD_WORKERS: ${{ env.MAX_BUILD_WORKERS }}
              run: |
                  set -euo pipefail
                  SDK_SHA="${{ steps.get-sha.outputs.sdk_sha }}"

                  # Record timestamp before dispatch to avoid race condition
                  DISPATCH_TIME=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
                  echo "dispatch_time=$DISPATCH_TIME" >> "$GITHUB_OUTPUT"

                  echo "Dispatching benchmarks build with SDK commit: $SDK_SHA at $DISPATCH_TIME"
                  PAYLOAD=$(jq -n \
                    --arg dataset "$DATASET" \
                    --arg split "$SPLIT" \
                    --arg max_workers "$MAX_BUILD_WORKERS" \
                    --arg n_limit "$EVAL_LIMIT" \
                    --arg sdk_commit "$SDK_SHA" \
                    '{ref:"main", inputs: {dataset:$dataset, split:$split, "max-workers":$max_workers, "n-limit":$n_limit, "sdk-commit":$sdk_commit}}')
                  RESPONSE=$(curl -sS -o /tmp/build-dispatch.out -w "%{http_code}" -X POST \
                    -H "Authorization: token $PAT_TOKEN" \
                    -H "Accept: application/vnd.github+json" \
                    -d "$PAYLOAD" \
                    "https://api.github.com/repos/${{ env.BENCHMARKS_REPO }}/actions/workflows/${{ env.BENCHMARKS_BUILD_WORKFLOW }}/dispatches")
                  if [ "$RESPONSE" != "204" ]; then
                    echo "Benchmarks build dispatch failed (status $RESPONSE):" >&2
                    cat /tmp/build-dispatch.out >&2
                    exit 1
                  fi

                  # Wait for run to be created in GitHub's system
                  echo "Waiting 10 seconds for workflow run to be created..."
                  sleep 10
                  echo "bench_build_dispatched=true" >> "$GITHUB_OUTPUT"

            - name: Wait for benchmarks build completion
              env:
                  DISPATCH_TIME: ${{ steps.build-dispatch.outputs.dispatch_time }}
              run: |
                  set -euo pipefail
                  WORKFLOW_ID="${{ env.BENCHMARKS_BUILD_WORKFLOW }}"
                  REPO="${{ env.BENCHMARKS_REPO }}"
                  MAX_ATTEMPTS="${{ env.MAX_POLL_ATTEMPTS }}"
                  SLEEP_SECONDS="${{ env.POLL_INTERVAL_SECONDS }}"

                  # Find the run that was created after our dispatch
                  echo "Looking for workflow run created after $DISPATCH_TIME"
                  RUN_ID=""
                  for i in $(seq 1 $MAX_ATTEMPTS); do
                    # Query for recent runs on main branch, get more results to avoid race
                    RUNS=$(curl -sS \
                      -H "Authorization: token $PAT_TOKEN" \
                      -H "Accept: application/vnd.github+json" \
                      "https://api.github.com/repos/${REPO}/actions/workflows/${WORKFLOW_ID}/runs?per_page=5&branch=main&created=>=$DISPATCH_TIME")

                    # Find the first run created at or after dispatch time
                    if [ -z "$RUN_ID" ]; then
                      RUN_ID=$(echo "$RUNS" | jq -r ".workflow_runs[] | select(.created_at >= \"$DISPATCH_TIME\") | .id" | head -1)
                      if [ -n "$RUN_ID" ] && [ "$RUN_ID" != "null" ]; then
                        echo "Found workflow run: $RUN_ID"
                      else
                        echo "Waiting for workflow run to appear (attempt $i/$MAX_ATTEMPTS)..."
                        sleep 5
                        continue
                      fi
                    fi

                    # Check status of our specific run
                    RUN_DATA=$(echo "$RUNS" | jq -r ".workflow_runs[] | select(.id == $RUN_ID)")
                    STATUS=$(echo "$RUN_DATA" | jq -r '.status')
                    CONCL=$(echo "$RUN_DATA" | jq -r '.conclusion')

                    echo "Benchmarks build run ${RUN_ID}: status=${STATUS}, conclusion=${CONCL}"
                    if [ "$STATUS" = "completed" ]; then
                      if [ "$CONCL" = "success" ]; then
                        exit 0
                      else
                        echo "Benchmarks build failed with conclusion ${CONCL}" >&2
                        exit 1
                      fi
                    fi
                    sleep $SLEEP_SECONDS
                  done
                  echo "Timed out waiting for benchmarks build to finish" >&2
                  exit 1

            - name: Dispatch evaluation workflow
              env:
                  SDK_SHA: ${{ steps.get-sha.outputs.sdk_sha }}
                  EVAL_LIMIT: ${{ steps.params.outputs.eval_limit }}
                  MODELS: ${{ steps.params.outputs.models }}
                  EVAL_REPO: ${{ env.EVAL_REPO }}
                  EVAL_WORKFLOW: ${{ env.EVAL_WORKFLOW }}
              run: |
                  echo "Dispatching evaluation workflow with SDK commit: $SDK_SHA"
                  PAYLOAD=$(jq -n \
                    --arg sdk "$SDK_SHA" \
                    --arg eval_limit "$EVAL_LIMIT" \
                    --arg models "$MODELS" \
                    '{ref: "main", inputs: {sdk_commit: $sdk, eval_limit: $eval_limit, models: $models}}')
                  RESPONSE=$(curl -sS -o /tmp/dispatch.out -w "%{http_code}" -X POST \
                    -H "Authorization: token $PAT_TOKEN" \
                    -H "Accept: application/vnd.github+json" \
                    -d "$PAYLOAD" \
                    "https://api.github.com/repos/${EVAL_REPO}/actions/workflows/${EVAL_WORKFLOW}/dispatches")
                  if [ "$RESPONSE" != "204" ]; then
                    echo "Dispatch failed (status $RESPONSE):" >&2
                    cat /tmp/dispatch.out >&2
                    exit 1
                  fi

            - name: Comment on PR
              env:
                  GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
                  SDK_SHA: ${{ steps.get-sha.outputs.sdk_sha }}
                  EVAL_LIMIT: ${{ steps.params.outputs.eval_limit }}
                  MODELS: ${{ steps.params.outputs.models }}
                  TRIGGER_DESC: ${{ steps.params.outputs.trigger_desc }}
                  EVENT_NAME: ${{ github.event_name }}
                  PR_NUMBER_INPUT: ${{ steps.params.outputs.pr_number }}
              run: |
                  set -euo pipefail
                  PR_NUMBER="$PR_NUMBER_INPUT"
                  if [ "$EVENT_NAME" = "release" ] && [ -z "$PR_NUMBER" ]; then
                    # Attempt to find the merged PR for this commit
                    PR_NUMBER=$(curl -sS \
                      -H "Authorization: Bearer $GITHUB_TOKEN" \
                      -H "Accept: application/vnd.github+json" \
                      "https://api.github.com/repos/${{ github.repository }}/commits/${SDK_SHA}/pulls" \
                      | jq -r '.[0].number // ""')
                  fi

                  if [ -z "$PR_NUMBER" ]; then
                    echo "No PR found to comment on; skipping comment"
                    exit 0
                  fi

                  COMMENT_BODY=$(printf '**Evaluation Triggered**\n\n- Trigger: %s\n- SDK: %s\n- Eval limit: %s\n- Models: %s\n' \
                    "$TRIGGER_DESC" "$SDK_SHA" "$EVAL_LIMIT" "$MODELS")

                  curl -sS -X POST \
                    -H "Accept: application/vnd.github+json" \
                    -H "Authorization: Bearer $GITHUB_TOKEN" \
                    "https://api.github.com/repos/${{ github.repository }}/issues/${PR_NUMBER}/comments" \
                    -d "$(jq -n --arg body "$COMMENT_BODY" '{body: $body}')"
